\relax 
\citation{web:oculus}
\citation{web:vive}
\citation{web:hololens}
\citation{disconfortReview}
\citation{vergenceDisconfort}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{vergenceDisconfort}
\citation{vergenceDisconfort}
\citation{neareyeblur}
\citation{sceneComposition}
\citation{eyeTracking}
\citation{LIBELAS}
\citation{LIBELAS}
\citation{bouguetcalibration}
\citation{calibrationopencv2}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Current version of the HMD video-see-through prototype.\relax }}{2}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:proto}{{1}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  In A and C can be seen the usual effect that happens when the coupling of the accommodation vergence is correct. As the accomodation distance is the same as the vergence distance, a blur effect appears in the corners. In B and D can be seen the effect that happens when an stereo scene is showed through near eye screens. As the accomodation distance is different than the vergence distance, no blur effect is applied in the corners. Source \cite  {vergenceDisconfort}.\relax }}{2}}
\newlabel{fig:vergence}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}State of the art}{2}}
\newlabel{sec:art}{{2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Objectives}{2}}
\citation{web:github}
\citation{web:githubDesktop}
\citation{web:trello}
\citation{web:qt}
\citation{web:opencv}
\citation{web:matlab}
\@writefile{toc}{\contentsline {section}{\numberline {4}Methodology}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Tools and Development}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Calibration}{3}}
\newlabel{sec:calib}{{5.1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Libelas}{3}}
\newlabel{sec:libelas}{{5.2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Configuration}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Pipeline and module integration}{4}}
\newlabel{sec:pipeline}{{5.4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Offline pipeline}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Diagram of the pipeline of the system. At top the grabbing threads that capture the images from the cameras. In the middle the thread that displays the images and changes between user settings. At the bottom the thread that process the images and classifies them. \relax }}{5}}
\newlabel{fig:pipeline}{{3}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Results}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}LIBELAS performance}{5}}
\newlabel{sec:resizeperformance}{{6.1}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Computing time of LIBELAS, the rectification and all the processing module in milliseconds in 175 frames from a near distance video.\relax }}{5}}
\newlabel{tab:timeprocess}{{1}{5}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Computing time of LIBELAS in percentage over the total processing time in 3 different videos with different distances.\relax }}{5}}
\newlabel{fig:libelaspercentatge}{{4}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}LIBELAS output}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}First user testing}{6}}
\newlabel{fig:output:mean}{{5a}{6}}
\newlabel{sub@fig:output:mean}{{a}{6}}
\newlabel{fig:output:min}{{5b}{6}}
\newlabel{sub@fig:output:min}{{b}{6}}
\newlabel{fig:output:max}{{5c}{6}}
\newlabel{sub@fig:output:max}{{c}{6}}
\newlabel{fig:output:roicrop}{{5d}{6}}
\newlabel{sub@fig:output:roicrop}{{d}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  Charts of the output of the operation over the center of the depth map with different operations on different sizes and distances.\relax }}{6}}
\newlabel{fig:output}{{5}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4}Second user testing}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.1}Accomodation-Vergence settings}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.2}User opinion of the settings }{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.3}Size issue}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.4.4}User opinion on the dynamic settings}{7}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Results of the configuration of the ROIs in the first user testing session. The second column represents the general feelings of the users when changing the settings. Note that $\Delta X$ means separation between the center of the image pair in the X axis and $\Delta Y$ means separation between centers in the Y axis.\relax }}{8}}
\newlabel{tab:firstUserTestResults}{{2}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Mean distance between center points of the images on each configuration. Note that $\Delta X$ means separation between the center of the image pair in the X axis.\relax }}{8}}
\newlabel{fig:ut:2:deltax}{{6}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Mean size of the images in each configuration for each distance. Note that a bigger size means a bigger ROI and therefore smaller objects.\relax }}{8}}
\newlabel{fig:ut:2:size}{{7}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Future work}{8}}
\bibdata{biblio}
\bibcite{web:trello}{1}
\bibcite{bouguetcalibration}{2}
\bibcite{web:qt}{3}
\bibcite{web:vive}{4}
\bibcite{eyeTracking}{5}
\bibcite{web:snellen}{6}
\bibcite{LIBELAS}{7}
\bibcite{vergenceDisconfort}{8}
\bibcite{web:oculus}{9}
\bibcite{web:github}{10}
\bibcite{web:githubDesktop}{11}
\bibcite{web:matlab}{12}
\bibcite{neareyeblur}{13}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Results in the second user testing session of the feelings of the users in percentage of positive responses. At top the distance where the testing was done and at the left the configuration used when that response was given. Fused means if the user are seeing the images correctly fused, and Size if the users are seeing the object's size similar to the reality.\relax }}{9}}
\newlabel{tab:ut:2:feelings}{{3}{9}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Preferences of the user when using the dynamic setting changer.\relax }}{9}}
\newlabel{tab:ut:2:dynamic}{{4}{9}}
\bibcite{web:hololens}{14}
\bibcite{sceneComposition}{15}
\bibcite{web:opencv}{16}
\bibcite{disconfortReview}{17}
\bibcite{calibrationopencv2}{18}
\bibstyle{plain}
\citation{web:snellen}
\citation{web:snellen}
\@writefile{toc}{\contentsline {section}{\numberline {A}User testing protocol}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}First user testing protocol}{10}}
\newlabel{sec:annex:user1}{{A.1}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Second user testing protocol}{10}}
\newlabel{sec:annex:user2}{{A.2}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {B}Additional images}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Ophthalmological pattern used in the user testing sessions. Source \cite  {web:snellen}.\relax }}{11}}
\newlabel{fig:add:pattern}{{8}{11}}
\newlabel{fig:rec:regular}{{9a}{11}}
\newlabel{sub@fig:rec:regular}{{a}{11}}
\newlabel{fig:rec:ractified}{{9b}{11}}
\newlabel{sub@fig:rec:ractified}{{b}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Figure \ref  {fig:rec:regular} is an example one image pair as it is captured from the cameras, the distortion produced by the optic of the cameras can be noticed. In these images the objects cannot be found on the same Y axis, for example the pattern in the middle of the image. In Figure \ref  {fig:rec:ractified} the same images from \ref  {fig:rec:regular} have been rectified using the calibration module. The distortion produced by the lenses of the camera is gone and the objects can be found in the same Y axis. \relax }}{11}}
\newlabel{fig:rec}{{9}{11}}
